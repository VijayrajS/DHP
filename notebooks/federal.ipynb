{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://thefederal.com/tag/caa/\"\n",
    "r1 = requests.get(url)\n",
    "coverpage = r1.content\n",
    "soup1 = BeautifulSoup(coverpage, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_links = []\n",
    "news_items = soup1.find_all('div', class_='td-block-span4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in news_items:\n",
    "    x = i.find('a')['href']\n",
    "    article_links.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "article_links = []\n",
    "while counter<55:\n",
    "    print(counter)\n",
    "    url = \"https://thefederal.com/tag/cab/page/\" + str(counter)\n",
    "    r1 = requests.get(url)\n",
    "    coverpage = r1.content\n",
    "    soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "    news_items = soup1.find_all('div', class_='td-block-span4')\n",
    "    \n",
    "    \n",
    "    for i in news_items:\n",
    "        x = i.find('a')['href']\n",
    "        article_links.append(x)\n",
    "    counter+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "uniq = []\n",
    "for i in article_links:\n",
    "    if i not in uniq:\n",
    "        uniq.append(i)\n",
    "print(len(uniq))\n",
    "print(len(article_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = i\n",
    "r1 = requests.get(url)\n",
    "coverpage = r1.content\n",
    "soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "texts = []\n",
    "ps = soup1.find('div', class_='td-post-content').find_all('p')\n",
    "for i in range(len(ps)):\n",
    "    if i < len(ps) -1:\n",
    "        texts.append(ps[i].text)\n",
    "\n",
    "t = soup1.find('time')['datetime']\n",
    "d ={}\n",
    "d['link'] = url\n",
    "d['text'] = \"\\n\".join(texts)\n",
    "d['time'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for i in uniq:\n",
    "    url = i\n",
    "    r1 = requests.get(url)\n",
    "    coverpage = r1.content\n",
    "    soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "    texts = []\n",
    "    ps = soup1.find('div', class_='td-post-content').find_all('p')\n",
    "    for i in range(len(ps)):\n",
    "        if i < len(ps) -1:\n",
    "            texts.append(ps[i].text)\n",
    "\n",
    "    t = soup1.find('time')['datetime']\n",
    "    d ={}\n",
    "    try:\n",
    "        d['link'] = url\n",
    "        d['text'] = \"\\n\".join(texts)\n",
    "        d['time'] = t\n",
    "        articles.append(d)\n",
    "    except:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('federal_cab.pickle', 'wb') as handle:\n",
    "    pickle.dump(articles, handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'link': 'https://thefederal.com/states/north/delhi/akali-dal-will-support-bjp-in-delhi-assembly-polls-says-party-president-nadda/', 'text': 'BJP president J P Nadda on Wednesday (January 29) said that ally Shiromani Akali Dal (SAD), which had decided to support the saffron party in the upcoming Delhi Assembly election. Earlier, SAD said it will contest in the election alone.\\nAt a joint press conference with Shiromani Akali Dal (SAD) president Sukhbir Badal, Nadda hailed the party as an old and strong ally, while Badal asserted that their alliance is not merely about politics but also about a bond of sentiments.\\n“It is not just a political alliance. It is bound by emotions, for peace, the future, and interests of Punjab and the country. There were some misunderstandings that have been sorted out,” Badal said.\\nEarlier, the Punjab-based party said it will not contest the elections as it was asked by the BJP to change its stand on the Citizenship Amendment Act (CAA), which it had vehemently refused.\\nBadal said SAD’s earlier decision to contest Delhi elections alone was due to a misunderstanding, that had now been sorted and that the alliance with the BJP was never in any real danger. “We never broke the alliance. We just decided to contest the election separately,” said Badal.\\nAkali Dal’s decision to not contest the polls had triggered concerns in the BJP that it may alienate a section of Sikh voters. Nadda held a long meeting with Badal before addressing the joint press conference.', 'time': '2020-01-29T18:41:13+00:00'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('federal_caa.pickle', 'wb') as handle:\n",
    "    pickle.load(articles, handle)\n",
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
