Don’t get too close to colleagues in office. AI snoops are here to ensure social distancing
New Delhi: Social distancing at the office can be difficult, especially if you are used to chatting with colleagues over lunch or coffee. The temptation to bend the rule just this one time lingers right around the corner, and you probably do throw caution to the wind and sneak into your packed office canteen when the bosses aren’t around. 
But don’t get too cocky. Your boss may be away but they probably still have eyes on you, and your little adventure may not go unnoticed after all.
Indian companies have started using CCTV cameras equipped with artificial intelligence (AI) to ensure employees maintain social distancing at the workplace as any lack of oversight may lead to a Covid-19 outbreak on the premises.
From Indian tech wizards to global e-commerce giant Amazon, many have come up with AI solutions that work in different ways. While some are in the nature of snoops, sending reports of violations right to the authorities, others seek to sound off employees, in real time, when someone gets too close for comfort.
Makers and users of the technology say AI is helpful, and counter the privacy concerns that surround its use. In the current context, they say, it is for a good cause. However, legal and privacy experts are not so sure, saying the experiment is rife for misuse.
Also Read: Bored of social distancing, millennials & Gen Z are driving new Covid waves around the world
Electrical goods maker Havells started integrating AI with their CCTV cameras in April. The AI technology was linked to 42 CCTV cameras that can each monitor 50-60 people across its eight plants, factory floors, cafeterias, common areas, and outside yards at manufacturing plants, as also the corporate office.
“The employees were OK with the adoption of this solution… It was not looked upon as intruding into their privacy or surveillance since this was for a good cause,” said Jayant Kapoor, associate vice-president for information technology at Havells.
The solution, he added, has been “quite effective”. 
The technology employed by Havells is ‘Trust AI’, which was developed by Gurugram-based Bharat Light and Power Group (BLP).
Trust AI monitors the distance between two employees, and sends an alert to a dashboard (also as an email) if social=distancing norms are not being maintained. The alerts are in the form of images captured by the camera. The dashboard can be accessed by a supervisor or a manager. 
Speaking to ThePrint, BLP president and CEO Tejpreet Singh Chopra said he is convinced the technology does not violate privacy. “We have taken many steps to ensure privacy since this is an important point for most corporates,” he added. Singh said the data gathered by Trust AI is not “stored on our servers”. 
“Corporates are using these technologies to create awareness about safety — not for taking specific actions against anybody. Also, it helps factory managers change the flow of material and people… to avoid hot spots.”
A similar solution has been devised by Chennai-based Ajna AI, which is currently conducting a commercial pilot with a leading automaker’s corporate office in the Tamil Nadu capital. According to Nebu K. Abraham, Ajna AI’s executive vice-president for the Middle-East region, the company is also carrying out preliminary pilots in Saudi Arabia and Dubai. 
Abraham makes light of privacy concerns as well. “We are not collecting data on faces or identities. We are only processing violations, and measuring distance between people. We are GDPR compliant,” he added, referring to the European Union’s General Data Protection Regulation, which has been touted as “the toughest privacy and security law in the world”. 
In June, Amazon introduced the ‘Distance Assistant’, a technology that alerts people when someone comes closer than they should under social-distancing guidelines. The technology is implemented through screens that reflect live footage of a given area. Once you walk in, your image on the screen is reflected with a green circle around you that outlines, through depth sensors, the distance (six feet) to be maintained with other people. Anytime someone comes too close, both the circles — yours and theirs — turn red, and you can immediately step back.
Amazon has also open-sourced the technology, which means more companies can easily develop similar solutions.
AI-based social-distance-monitoring, Abraham said, can help since it is automated and requires less human intervention to flag violations. “People do unintentionally flout social distancing quite frequently,” he added. 
When Ajna AI was conducting research on how often social-distancing norms are flouted, with a small shop in South India as the study site, the team noticed that 5-7 people were consistently present on the premises over a three-hour period even though it had a capacity of no more than four people, said Abraham. 
Also Read: 1m, 1.5m, 2m — the different levels of social distancing countries are following amid Covid
However, there are concerns that using AI to monitor social distancing could lead to more surveillance. 
That companies will use AI and CCTV cameras ethically is not something anyone can guarantee, said Vineet Kumar, founder-president of the Ranchi-based think-tank CyberPeace Foundation. 
“By and large, the law requires every organisation to have an information security policy in place when any personal data is collected, which would invariably have the mandate of security, destruction, retention, scope of storage etc,” he added. 
“There is no way to be sure how each and every company deals with the data they may acquire through means such [as] CCTV cameras — some companies may deal with it ethically, others may not, there is no way to be sure.”
Prasanth Sugathan, legal director at the Delhi-based digital rights organisation SFLC.in, noted that the Indian law is yet to be equipped with provisions governing AI. 
“AI integration with CCTV cameras has a plethora of possibilities and may have some ethical and data protection concerns,” he said.
“The technology being talked about can be used to gather ‘facial patterns’ and the data collected through it could also be used to collect [information on] ‘physical, physiological and mental health conditions’,” he added.
Data collection on the emotional condition of employees, he said, can be used to make judgements on stress management, competence and productivity of individuals, which may “be an excessive intrusion into an individual’s personal space and liberty”.
“Data about our bodies and emotional state can also be exploited by healthcare and insurance companies to predict our health status and future diseases,” Sugathan added. “Legally, it is a grey area as India doesn’t have any law that explicitly regulates the use of AI.”
Abraham suggested that the threat AI poses for privacy depends on how the technology is used. 
If police are allowed to conduct such surveillance for uses that may breach privacy, then this technology may be customised for that too, he said. “But what we currently offer does not violate privacy,” he added.
